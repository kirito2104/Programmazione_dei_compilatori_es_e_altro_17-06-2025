





# ---
# 
# ## **2. Analisi della complessit√† per ogni istruzione**
# 
# | Istruzione                     | Complessit√† | Note |
# |--------------------------------|-------------|------|
# | `d = {}`                        | O(1) | Creazione di un dizionario vuoto |
# | `c = 0`                         | O(1) | Assegnamento semplice |
# | `for x in a:`                   | O(n) | Il ciclo viene eseguito per ogni elemento di `a` |
# | `if x in d:`                    | O(1) **(caso medio)** / O(n) **(caso peggiore)** | Controllo presenza nel dizionario |
# | `c += 1`                        | O(1) | Incremento semplice |
# | `d[x] = None`                   | O(1) **(caso medio)** / O(n) **(caso peggiore)** | Inserimento nel dizionario |
# | `print(d)`                      | O(n) | Dipende dal numero di elementi in `d`, ma non incide molto sul costo totale |
# 
# ---
# 
# ## **3. Caso Medio: Complessit√† Lineare O(n)**
# Nella maggior parte dei casi:
# - L‚Äôoperazione `x in d` √® **O(1)** perch√© i dizionari Python usano **hash table**.
# - L'operazione `d[x] = None` √® **O(1)**.
# 
# Il ciclo principale viene eseguito `n` volte, quindi la complessit√† totale √® **O(n)**.
# 
# ---
# 
# ## **4. Caso Peggiore: Complessit√† Quadratica O(n¬≤)**
# Nel peggiore dei casi:
# - Se ci sono molte **collisioni di hash**, l'operazione `x in d` potrebbe dover 
# **scansionare una lista interna** all'interno della tabella hash, portando la ricerca a **O(n)** per elemento.
# - Se `x in d` diventa O(n), e viene eseguito per ogni elemento in `a`, la complessit√† totale diventa **O(n) * O(n) = O(n¬≤)**.
# 
# Un caso in cui il peggiore scenario pu√≤ verificarsi:
# - Se la funzione viene eseguita su un **input molto grande** con **molti elementi con lo stesso hash** 
# (es. con hash mal distribuiti, cosa che pu√≤ accadere raramente nei dizionari Python).
# 
# ---
# 
# ## **5. Risposta Corretta**
# La tua scelta **"Quadratica nel caso peggiore"** √® **giusta** perch√©:
# ‚úÖ Nel **caso medio**, la complessit√† √® **O(n)**.  
# ‚úÖ Nel **caso peggiore**, a causa delle collisioni hash, pu√≤ diventare **O(n¬≤)**.  
# ‚ùå Non √® "Quadratica sempre", perch√© il caso medio √® **solo O(n)**.  
# 
# ---
# 
# ## **6. Conclusione**
# Hai risposto correttamente perch√© **la funzione √® quadratica solo nel caso peggiore** 
# quando ci sono **molte collisioni di hash nel dizionario**. In media, invece, √® lineare.
# 
# **Risposta corretta:**
# ‚úî **Quadratica nel caso peggiore** ‚úÖ  
# ‚ùå **Quadratica sempre** √® sbagliato, perch√© la maggior parte delle volte √® **lineare**.



########################################################################################################################################################
#¬∞¬∞ ECCO DEGLI ESEMPI SIEGATI CON LE VARIE COMPLESSIT√† :
'''
### **Casistiche comuni e come riconoscere la complessit√† dello spazio e del tempo**
'''

# La complessit√† dello **spazio** e del **tempo** occupato da una struttura dati dipende 
# da come vengono allocati, memorizzati e processati gli elementi.

# La complessit√† temporale misura il numero di operazioni eseguite in funzione della dimensione 
# dell'input.

# La complessit√† spaziale misura la quantit√† di memoria utilizzata in funzione dell'input.
# Vediamo diverse casistiche con esempi e come riconoscerle.

'''
## **1 Strutture lineari - O(n)**
'''

# üìå **Regola**: Se una struttura cresce con la dimensione dell'input e ogni elemento √® memorizzato
# o processato una sola volta, lo spazio e il tempo sono lineari.

'''
### **Esempio 1: Lista di `n` elementi**
'''
# Creazione di una lista con n elementi

'''
a = [i for i in range(n)]
'''
# ‚úî **Analisi**:
# - **Spazio**: La lista `a` contiene `n` elementi, quindi occupa **O(n)** memoria.
# - **Tempo**: La creazione della lista richiede un'iterazione su `n`, quindi **O(n)**.

'''
### **Esempio 2: Scansione di una lista**
'''
# Iterazione su una lista
'''

a = [i for i in range(n)]
for elem in a:
    print(elem)
    
'''

# ‚úî **Analisi**:
# - **Spazio**: La lista `a` occupa **O(n)** spazio.
# - **Tempo**: L'iterazione su tutti gli `n` elementi richiede **O(n)** tempo.

'''
## **2 Strutture quadratiche - O(n¬≤)**
'''

# üìå **Regola**: Se ogni elemento genera o contiene un'altra struttura di dimensione `O(n)`,
# il totale pu√≤ diventare **O(n¬≤)**.

'''
### **Esempio: Matrice quadrata e doppio ciclo**
'''
# Creazione di una matrice quadrata
def matrix(n):
    # Creazione di una matrice quadrata n x n inizializzata con zeri
    # Questo utilizza una list comprehension: per ogni riga (n righe), crea una lista con n zeri
    matrix = [[0] * n for _ in range(n)]  

    # Doppio ciclo annidato per iterare su ogni elemento della matrice
    # range(n) restituisce una sequenza di numeri interi da 0 a n-1
    # Nel ciclo esterno 'i' rappresenta l'indice di riga
    for i in range(n):
        # Nel ciclo interno 'j' rappresenta l'indice di colonna
        for j in range(n):
            # L'elemento nella posizione (i, j) viene aggiornato con la somma degli indici di riga e colonna
            # Questo significa che la diagonale principale avr√† sempre numeri pari (i+j con i==j ‚Üí 2*i),
            # e gli altri elementi aumentano con la distanza dalla posizione (0,0)
            matrix[i][j] = i + j
    '''
    # Per evitare n^2 bisogna mettere il for non sotto al altro for ma staccato,
    # questo permette di evitare che i due for avvengano in parallelo e che il tempo diventa n^3.
    
    '''
    # Restituisce la matrice risultante
    return matrix
print(matrix(3))
# Output:
# [[0, 1, 2],
#  [1, 2, 3],
#  [2, 3, 4]]


# ‚úî **Analisi**:
# - **Spazio**: La matrice ha `n √ó n` elementi, quindi occupa **O(n¬≤)** memoria.
# - **Tempo**: Ogni elemento viene elaborato una volta, ma il doppio ciclo comporta **O(n¬≤)** operazioni.

'''
## **3 Strutture cubiche - O(n¬≥)**
'''

# üìå **Regola**: Se ogni elemento ha una struttura di O(n¬≤) e viene visitato in tre cicli annidati,
# il totale diventa O(n¬≥).

'''
### **Esempio: Matrice tridimensionale**
'''
# Creazione di una matrice tridimensionale
'''
cube = [[[0] * n for _ in range(n)] for _ in range(n)]

# Triplo ciclo annidato
for i in range(n):
    for j in range(n):
        for k in range(n):
            cube[i][j][k] = i + j + k
'''
# ‚úî **Analisi**:
# - **Spazio**: La matrice tridimensionale contiene `n √ó n √ó n` elementi, quindi **O(n¬≥)**.
# - **Tempo**: Ogni elemento viene aggiornato in un triplo ciclo, risultando in **O(n¬≥)** operazioni.

'''
## **4 Strutture logaritmiche - O(log n)**
'''

# üìå **Regola**: Se la struttura divide ripetutamente i dati in due parti, il tempo √® spesso **O(log n)**.

'''
### **Esempio: Ricerca binaria**
'''
# Funzione per ricerca binaria
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1

# ‚úî **Analisi**:
# - **Spazio**: La ricerca binaria non utilizza memoria aggiuntiva, quindi **O(1)**.
# - **Tempo**: L'intervallo di ricerca si dimezza a ogni iterazione, risultando in **O(log n)** operazioni.

'''
## **5 Strutture quasi lineari - O(n log n)**
'''

# üìå **Regola**: Se l'algoritmo richiede ordinamenti o altre operazioni che combinano una scansione
# lineare con divisioni logaritmiche, il tempo pu√≤ essere **O(n log n)**.

'''
### **Esempio: Merge Sort**
'''
# Implementazione di Merge Sort
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)

def merge(left, right):
    result = []
    i = j = 0
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    result.extend(left[i:])
    result.extend(right[j:])
    return result

# ‚úî **Analisi**:
# - **Spazio**: Merge Sort utilizza spazio addizionale per le liste suddivise, quindi **O(n)**.
# - **Tempo**: Ogni divisione dimezza il problema e richiede una ricombinazione lineare, 
# risultando in **O(n log n)**.

'''
## **6 Strutture sommate - O(n + m)**
'''

# üìå **Regola**: Se il problema coinvolge due strutture di dimensioni diverse,
#               la complessit√† √® la somma dei loro contributi.

'''
### **Esempio: Unione di due liste**
'''
# Unione di due liste
def merge_lists(list1, list2):
    return list1 + list2

# ‚úî **Analisi**:
# - **Spazio**: La lista risultante ha dimensione `n + m`, quindi **O(n + m)**.
# - **Tempo**: La concatenazione richiede la copia di entrambi gli array, quindi **O(n + m)**.


##############################################################################################


## ** 7  Strutture costanti - O(1)**
'''

# üìå **Regola**: Se la dimensione della struttura √® indipendente dall'input e 
# le operazioni avvengono in tempo fisso, lo spazio e il tempo sono costanti **O(1)**.

'''
### **Esempio: Accesso a un elemento di un array**
'''
# Accesso diretto a un elemento di una lista
a = [1, 2, 3, 4, 5]
x = a[2]

# ‚úî **Analisi**:
# - **Spazio**: La lista `a` √® di dimensione fissa, quindi **O(1)**.
# - **Tempo**: L'accesso a un elemento in un array indicizzato √® istantaneo, quindi **O(1)**.

'''

## **78ÔøΩÔøΩÔøΩ Strutture esponenziali - O(2^n)*
    # **Regola**: Se l'algoritmo richiede ordinamenti o altre operazioni 
    # che combinano una scansione lineare con divisioni esponenziali, 
    # il tempo pu√≤ essere **O(2^n)**.
 
'''   
## **Come riconoscere la complessit√† dello spazio e del tempo?**
'''

# 1. **Osserva le dimensioni della struttura dati** ‚Üí Se cresce con `n`, lo spazio √® almeno **O(n)**.
# 2. **Conta i cicli annidati** ‚Üí Se ci sono due cicli `for`, il tempo √® **O(n¬≤)**, se tre **O(n¬≥)**, ecc.
# 3. **Verifica le divisioni di dati** ‚Üí Se il problema si dimezza a ogni iterazione, 
#       il tempo √® **O(log n)**.

# 4. **Guarda le operazioni costanti** ‚Üí Se eseguite una sola volta indipendentemente da `n`,
# il tempo √® **O(1)**.
# 5. **Differenzia tra operazioni sequenziali e parallele** ‚Üí Se gli elementi vengono processati
#                                       contemporaneamente in pi√π thread, il tempo potrebbe ridursi.
